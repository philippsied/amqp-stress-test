\documentclass[	a4paper,
			11pt,
			oneside,
			parskip]{scrartcl}
\usepackage{package/ownstil}
\usepackage{package/owncmd}

\begin{document}
	
	
\section*{Zielstellung und Rahmenbedingungen}
	
	Die vorliegende Dokumentation fasst die Ergebnisse der im Praktikum \glqq Angriffe auf AMQP-Messagebroker\grqq\ erarbeiteten Angriffe zusammen. Das Praktikum war Bestandteil des kooperativ gelehrten
	Modules \glqq Betriebliche Informationssysteme\grqq\ an der HTWK Leipzig und Uni Leipzig. Ziel des Praktikums war die Ermittlung von potenziellen Angriffsvektoren auf AMQP-Messagebroker - im speziellen RabbitMQ -, die Entwicklung der dafür benötigten Software, die Durchführung der Angriffe und Auswertung der Auswirkungen auf den Server selbst sowie andere unbeteiligte Clients.

	Die Implementierung der Angriffe erfolgte in der Programmiersprache Java und nutzt dabei die offizielle RabbitMQ Java-Bibliothek.
	Durch die Parametrisierung der Angriffe sollen gezielt Faktoren ermittelt werden, die das System besonders negativ beeinflussen und so die Verfügbarkeit stören. Der Fokus liegt somit in der 
	Verursachung eines \glqq Denial of Service\grqq\ des Systems.

	Um eine Bewertung der Angriffe und Auswirkungen zu ermöglichen, wurde zu Beginn eine Evaluation der verwendeten Werkzeuge durchgeführt sowie die Testumgebung eingerichtet. 
	Die Visualisierung spielte dabei ebenfalls eine Rolle, um die Ergebnisse anschaulich aufzubereiten. Auf Grundlage der Erkenntnisse sowie Beobachtungen sollen mögliche Empfehlungen
	ausgesprochen werden.



% ---------------------------------------------------------------------------------------------- %
%	
% --------------------------- Verwendete bzw. Erstellte Programme ------------------------------ %
%
% ---------------------------------------------------------------------------------------------- %
\clearpage
\section*{Verwendete bzw. Erstellte Programme}
	
	RabbitMQ bietet bereits eine Management-Oberfläche, mit denen sich viele Kennzahlen zur Leistungsfähigkeit des Server messen lassen. Weiterhin enthält der Java-Client unterhalb von
	\textit{rabbitmq-client-tests.jar} bereits eine Vielzahl an zahlreichen kleine Beispielprogramme für das Benchmarking der Funktionalität des eigenen Servers.  
	
	\paragraph{VirtualBox:} Der von uns verwendete Server wurde durch die Virtualisierungslösung VirtualBox realisiert. Neben der einfachen Installation neuer Gast-Systeme besteht die Möglichkeit Sicherheitspunkte zu erstellen. Bei einem Ausfall des System kann so der ursprüngliche Sicherungspunkt wiederhergestellt werden. Weiterhin kann die Bereitstellung der Ressourcen und der Anbindung an das Netzwerk beliebig eingestellt werden.
	
	\paragraph{Glances:} Das in Python geschriebene Glances ist ein System-Monitoring-Tool, welches zahlreiche Informationen auf engstem Raum präsentiert. Im einfachsten Fall werden die gesammelten System-Informationen auf der Konsole ausgeben.
	 Im vorliegenden Fall wird Glances für den Export der Messwerte in eine CSV-Datei verwendet. Ferner ermöglicht Glances die Bereitstellung eines integrierten Web-Interfaces zur Fernüberwachung der Umgebung.
	 Zu den gesammelten Informationen gehören unter anderem: CPU-Auslastung, Prozesse, Speicherverbrauch (HDD, RAM), Netzwerk- und Disk-IO sowie weitere Informationen zum System.

	\paragraph{HTML Performance Tools:} Die HTML Performance Tools ermöglichen die Definition einer Vielzahl von Anwendungsszenarios, welche systematisch abgearbeitet werden und deren gemessene Kennzahlen in einer JSON-Datei gespeichert werden. Die Besonderheit ist die integrierte grafische Visualisierung der Ergebnisse im Webbrowser. Die Tools basieren auf dem im Java-Client enthaltenen \hl{Perftest}.
	
	\paragraph{AMQPstress:} Um die Auswirkungen der gewählten Angriffsvektoren testen zu können, wurde für jeden Angriff ein eigener Client implementiert. Grundlage bildet die Java-Library von RabbitMQ, die geeignete Funktionen zur Kommunikation mit dem Servers bereitstellt. Alle Angriffe lassen sich über Parameter in ihrer Ausführung steuern. Welche Einstellungen zutreffen, lässt sich diesem Dokument sowie der integrierten Hilfe entnehmen. Auch zeigt sich, welche Parameter für einen erfolgreichen Angriff nötig sind. Hierzu gehören u.\,a. die Anzahl an Producer und Consumer oder auch die gewählte Nachrichtengröße.

	\paragraph{HTML-Reporting:} Um eine anpassbare Visualisierung der Messwerte zu ermöglichen, wurde die Visualisierungkomponente der \hl{HTML Performance Tools} angepasst und ausgebaut. Sie ermöglicht nun eine Visualisierung und Reporting der von Glances und von Perftest bereitgestellten Informationen. Die Ergebnisse werden hierbei in drei Diagrammen präsentiert und jeweils der Durchschnitt der Kennzahlen berechnet und dargestellt. Die einzelnen Messwerte sind innerhalb der HTML über Mouse-Hover zugänglich. 



% ---------------------------------------------------------------------------------------------- %
%	
% -------------------------------------- Testumgebung ------------------------------------------ %
%
% ---------------------------------------------------------------------------------------------- %
\clearpage
\section*{Testumgebung}
	Als Betriebssystem für den RabbitMQ-Servers wurde ein \tsl{Ubuntu Server 14.04.2 LTS} mit Kernel 3.16.0-30 verwendet. Das Testsysten wurde dabei als Virtuelle Maschine (VM) in der Virtualisierungslösung \glqq Virtualbox\grqq\ der Firma Oracle betrieben, um eine einfache Skalierung der Hardware, eine einfache Portabilität des Testsystem und einen reproduzierbaren Systemzustand, über die integrierte Snapshot-Funktion, bereitzustellen. Für die Konfiguration wurden die in Tabelle \ref{tab:testvm} dargestellten Einstellungen gewählt. 
	\begin{table}[!htb]
	\centering
	\begin{tabular}{p{3cm}|p{6cm}}
		\tsl{Host} 		& rabbitmqserver (192.168.178.153) \\\hline
		\tsl{Anz. CPU} 		& 2 \\
		\tsl{RAM} 		& 2048 MB \\
		\tsl{Grafikspeicher} 	& 12 MB \\
		\tsl{HDD} 		& 8,00 GB \\
		\tsl{Netzwerk}		& 1GB über Bridging durch lokales Netzwerk-Interface
	\end{tabular}
	\caption{Konfiguration der Test-VM}
	\label{tab:testvm}
	\end{table}

	Für die reproduzierbare Einrichtung der Testumgebung wurde ein BASH-Skript erstellt, welches sich im Repository des zugehörigen GitHub-Projektes befindet. Es setzt eine frische Installation 
	des Ubuntu Server voraus - ohne eine Vorauswahl an Softwarepacketen (z.\,B. LAMP). Vor der Ausführung des Skriptes sollte ein Snapshot erstellt werden. Anschließend kann es in der VM über:
	\begin{quote}
		\ttfamily 		
		\$\,> wget \url{https://raw.githubusercontent.com/philippsied/amqp-stress-test/master/utilities/setupTestEnv.sh}
	\end{quote}
	aus dem Git-Repository heruntergeladen werden. Da das Skript für die Einstellung des Netzwerkinterfaces Root-Rechte benötigt (Sudo-Rechte genügen nicht), muss der Root-User zuvor aktivert werden.
	Abschließend kann das Skript mit Sudo-Rechten ausgeführt werden:
	\begin{quote}
		\ttfamily 
		\$\,> sudo passwd root\\
		\$\,> sudo bash setupTestEnv.sh
	\end{quote}
	
	Nach Abschluss der Einrichtung erfolgt eine übersichtliche Ausgabe aller Informationen, einschließlich der RabbitMQ-Benutzerdaten und Adressen.

	



% ---------------------------------------------------------------------------------------------- %
%	
% ------------------------------ Beschreibung des Benchmarking --------------------------------- %
%
% ---------------------------------------------------------------------------------------------- %
\clearpage
\section*{Beschreibung des Benchmarking}
	
	Für die Durchführung des Benchmarking wurde stets der nachfolgend beschriebene Ablauf verwendet. Hierbei kamen drei physisch unabhängige Computer als Messpunkte zum Einsatz: der RabbitMQ-Server,
	der Client von dem der Angriff ausgeht und der Client zur Messung des Anwendungsszenarios. Dadurch soll eine gegenseitige Beeinflussung bereits im Vorfeld ausgeschlossen werden. Da die Messungen
	stets für ca. 10min ausgelegt waren, wurden sämtliche Stromsparmechanismen für die ersten 10min deaktiviert.
	
	Zu Beginn muss die VM des RabbitMQ-Servers gestartet werden. Vor jeder Messung wurde die VM dabei auf einen Snapshot zurückgesetzt, bei der sich das System in einem Zustand befindet,
	den es 5 Minuten nach dem Hochfahren der VM besitzt (Uptime ca. 5min).
	Für die Beobachtung des Ressourcenverbrauches auf dem RabbitMQ-Server wurde das Kommandozeilenprogramm \tsl{glances} verwendet.
	Der Programmaufruf für jeden Test lautet wie folgt:
	\begin{quote}
		\ttfamily
		\$\,> sudo glances -t 5 -\,-disable-process -\,-export-csv measure.csv
	\end{quote}
	Er veranlasst die Ansicht alle 5 Sekunden zu erneuern und die Anzeige der aktuell laufenden Prozesse abzuschalten, um den Ressourcenverbrauch durch \textsl{glances} selbst zu reduzieren.
	Die Messwerte werden dabei in die \tsl{measure.csv}-Datei exportiert, welche später zur Visualisierung und Auswertung verwendet wird.
	
	Anschließend wird die Messung des Anwendungsszenarios gestartet. Dazu wurde das Skript \hl{startBenchmark.sh}\footnote{\url{https://github.com/philippsied/amqp-stress-test/tree/master/perfBenchmark/runscenario}}
	verwendet. Der Aufruf lautet wie folgt:
	\begin{quote}
		\ttfamily
		\$\,> bash startBenchmark.sh "measure.json"\ \textbackslash\\ 
		                    \hspace*{6cm} testc:testp@192.168.178.153:5672/\%2f
	\end{quote}
	
	Als letztes wird der Angriff gestartet. Dafür kamen je nach Angriff unterschiedliche Parameter zum Einsatz. Die Angriffe wurde über separate \glqq runconfigs\grqq\footnote{\url{https://github.com/philippsied/amqp-stress-test/tree/master/perfBenchmark/runconfigs}} aus eclipse heraus gestartet. 
	
	Die Messung des Anwendungsszenario ist auf 10min festgelegt.\footnote{\url{https://github.com/philippsied/amqp-stress-test/tree/master/perfBenchmark/runscenario/publish-consume-spec.template}}
	Sobald die Messung des Anwendungsszenarios abgeschlossen ist, kann glances über die Eingabe von \glqq q\grqq\ beendet werden, der Angriff unterbrochen werden und die Ergebnisse in der \tsl{measure.csv}-Datei
	bzw. \tsl{measure.json}-Datei von den Computern aggregiert werden.
	
	Abschließend gilt es die Ergebnisse grafisch aufzubereiten und auszuwerten. Dafür müssen die \tsl{measure.csv} und die \tsl{measure.json} Dateien z.\,B. unterhalb des reporting Ordners kopiert
	werden\footnote{\url{https://github.com/philippsied/amqp-stress-test/tree/master/perfBenchmark/reporting}} und mittels des \hl{transformToJson.sh} BASH-Skriptes in eine \glqq measure.json\grqq\
	transformiert werden:
	\begin{quote}
		\ttfamily
		\$\,> bash transformToJson.sh "DoS"\ measure.csv measure.json
	\end{quote}
	Über die \hl{Results.html}-Datei können die Ergebnisse nun betrachtet und ausgewertet werden. Sofern die eingestellten Skalierungen für die Achsen nicht genügen, können diese über die div-Attribute
	in der HTML-Datei angepasst werden.
	
	
	
\clearpage
\section*{Beschreibung der Anwendungsszenarien}
	\usecase{Leerlauf}%
		{Der RabbitMQ-Server befindet sich im Leerlauf, d.\,h. ohne irgendeine Form von Last.}%
		{Keine}%
		{Keine}%
		{%
		 \measure{CPU}{0.5\%}\\
		 \measure{RAM}{120MB (Verwendet)}\\
		 \measure{HDD}{785MB (Frei)}\\
		 \measure{NET}{RCX 3Kbit/s\quad TRX 197Kbit/s}%
		}%
		{Keine}
	
	\usecase{Anwendungsszenario}%
		{Ein Producer erzeugt kontinuierlich Nachrichten, die von einem Consumer kontinuierlich korrekt entnommen werden. Es finden keine weiteren Anfragen bzw. Zugriffe auf den RabbitMQ-Server statt.}%
		{%
		 Messdauer: 600s (10min)\\
		 1 Consumer \\
		 1 Producer \\
		 Nachrichtengröße: 1024 Byte\\
		 Max. 50 Nachrichten/s (Producer)
		}%
		{bash startBenchmark.sh testc:testp@192.168.178.153:5672/\%2f}%
		{%
		 \measure{CPU}{2\%}\\
		 \measure{RAM}{127MB (Verwendet)}\\
		 \measure{HDD}{785MB (Frei)}\\
		 \measure{NET}{RCX 299Kbit/s\quad TRX 370Kbit/s}%
		}%
		{
		 Die Sender/Empfangsrate sowie die Latenz sind wie erwartet weitgehend konstant. Die Latenz liegt durchschnittlich bei 1.3 ms.
		 (Siehe Abb. \ref{fig:std-server1}, \ref{fig:std-server2}, \ref{fig:std-scenario})
		}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/std/std_server1.png}
			\caption{Ohne Angriff - Verlauf des Speicherbedarfs für RAM/HDD und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:std-server1}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/std/std_server2.png}
			\caption{Ohne Angriff - Verlauf der Transfer-, Empfangsrate und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:std-server2}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/std/std_scenario.png}
			\caption{Ohne Angriff - Verlauf der Transfer-, Empfangsrate und Verlauf der Latenz im Anwendungsszenario}
			\label{fig:std-scenario}
		\end{figure}
	


% ---------------------------------------------------------------------------------------------- %
%	
% -------------------------------- Beschreibung der Angriffe ----------------------------------- %
%
% ---------------------------------------------------------------------------------------------- %
\clearpage
\section*{Beschreibung der Angriffe}

	\attack{Referenzangriff - Kooperativer Client}%
		{%
		 Ein Producer erzeugt kontinuierlich Nachrichten festgelegter Größe mit zufälligem Inhalt, die über einen \glqq fanout\grqq-Exchange an 5 Consumer verteilt werden. Die Consumer quittieren dem RabbitMQ-Server dabei den Erhalt der Nachricht. 
		 Dieser Angriff dient zur Ermittlung einer Leistungsreferenz.
		}{%
		 -dm ACK (Aufrufparameter für Angriff) \\
		 -c 5 (5 Consumer) \\
		 -i 10 (10ms Pause zwischen 2 Consumer/Producer-Anfragen) \\
		 -ms 10240 (Nachrichtengröße: 10KB) \\
		 -u <uri> (URI für Verbindung mit Server) \\
		 1 Producer (Standard) \\
		 Nicht-Persistente Nachrichten (Standard) \\
		 Prefetching: Max. 512MB (Standard)
		}{%
		 Amqpstress -dm ACK -c 5 -i 10 -ms 10240 -u amqp://\\\hspace*{3cm}testc:testp@192.168.178.153:5672/\%2f
		}


	\attack{Ignorieren von Nachrichten}%
		{%
		 Ein Producer erzeugt kontinuierlich Nachrichten festgelegter Größe mit zufälligem Inhalt, die von einem oder mehreren Consumern empfangen, aber nicht quittiert werden.
		 Der RabbitMQ-Server ist somit gezwungen, die Nachrichten in der Queue zwischenzuspeichern.
		}{%
		 -dm NO (Aufrufparameter für Angriff) \\
		 -c 5 (5 Consumer) \\
		 -i 10 (10ms Pause zwischen 2 Consumer/Producer-Anfragen) \\
		 -ms 10240 (Nachrichtengröße: 10KB) \\
		 -u <uri> (URI für Verbindung mit Server) \\
		 1 Producer (Standard) \\
		 Nicht-Persistente Nachrichten (Standard) \\
		 Prefetching: Max. 512MB (Standard) 
		}{%
		 Amqpstress -dm NO -c 5 -i 10 -ms 10240 -u amqp://\\\hspace*{3cm}testc:testp@192.168.178.153:5672/\%2f
		}


	\attack{Sofortiges Abweisen von Nachrichten}%
		{%
		 Ein Producer erzeugt kontinuierlich Nachrichten festgelegter Größe mit zufälligem Inhalt, die von einem oder mehreren Consumern empfangen, aber sofort abgewiesen (basic.Reject) werden.
		 Der RabbitMQ-Server ist somit gezwungen, die Nachrichten in der Queue zwischenzuspeichern und erneut an den Consumer zu senden.
		}{%
		 -dm REJECT (Aufrufparameter für Angriff) \\
		 -c 5 (5 Consumer) \\
		 -i 10 (10ms Pause zwischen 2 Consumer/Producer-Anfragen) \\
		 -ms 10240 (Nachrichtengröße: 10KB) \\
		 -u <uri> (URI für Verbindung mit Server) \\
		 1 Producer (Standard) \\
		 Nicht-Persistente Nachrichten (Standard) \\
		 Prefetching: Max. 512MB (Standard)
		}{%
		 Amqpstress -dm REJECT -c 5 -i 10 -ms 10240 -mp -u amqp://\\\hspace*{3cm}testc:testp@192.168.178.153:5672/\%2f
		}
		
	
	\attack{Gebündeltes Abweisen von Nachrichten}%
		{%
		 Ein Producer erzeugt kontinuierlich Nachrichten festgelegter Größe mit zufälligem Inhalt, die von einem oder mehreren Consumern empfangen und zunächst ignoriert werden. Erreicht die Anzahl der 
		 ignorierten Nachrichten einen definierten Schwellwert, werden diese gebündelt abgewiesen (basic.NACK). Dadurch ist der RabbitMQ-Server gezwungen alle Nachrichten zwischenzuspeichern und stoßweise alle Nachrichten bis zu der aktuellen Sequenznummer erneut zuzustellen. Die Implementierung von basic.NACK stellt eine Besonderheit von RabbitMQ dar, welche nicht Bestandteil von AMQP-0-9-1 ist.
		}{%
		 -dm NACK (Aufrufparameter für Angriff) \\
		 Schwellwert: 1000 Nachrichten (Standard) \\
		 -c 5 (5 Consumer) \\
		 -i 10 (10ms Pause zwischen 2 Consumer/Producer-Anfragen) \\
		 -ms 10240 (Nachrichtengröße: 10KB) \\
		 -u <uri> (URI für Verbindung mit Server) \\
		 1 Producer (Standard) \\
		 Nicht-Persistente Nachrichten (Standard) \\
		 Prefetching: Max. 512MB (Standard)
		}{%
		 Amqpstress -dm NACK -c 5 -i 10 -ms 10240 -u amqp://\\\hspace*{3cm}testc:testp@192.168.178.153:5672/\%2f
		}
		

	\attack{Queue-Churning}%
		{%
		 Ein Client erzeugt bis zu einem Schwellwert Queues und befüllt Sie optional mit einer zufälligen Nachricht gegebener Größe. Wenn die Anzahl der erzeugten Queues einen definierten Schwellwert erreicht,
		 werden alle Queues ohne zu Warten gelöscht und der Zyklus beginnt erneut. Während bereits neue Queues angelegt und ggf. befüllt werden, muss der RabbitMQ-Server die Überreste der Queues im RAM bzw.
		 der Festplatte bereinigen. 
		}{%
		 -dq NO (Aufrufparameter für Angriff -Ohne Nachrichten) \\
		 -i 1 (1ms Pause zwischen Queue-Erzeugung) \\
		 -pc 100000 (Schwellwert: 100000 Queues) \\
		 -u <uri> (URI für Verbindung mit Server) \\
		 1 Client - Consumer und Producer zugleich (Standard) \\
		 Nicht-Persistente Nachrichten/Queues (Standard)
		}{%
		 Amqpstress -dq NO -i 1 -pc 100000 -u amqp://\\\hspace*{3cm}testc:testp@192.168.178.153:5672/\%2f
		}
		
		
		
	\attack{Nachrichten mit großem Header}%
		{%
		 RabbitMQ bietet die Möglichkeit im Header einer Nachricht bestimmte Parameter für die Weiterleitung zu deklarieren. Dieser Test beschäftigt sich mit den Auswirkung auf den Server bzw. die Clients,
		 die übergroße Header verursachen. Dies wird dadurch begünstigt, dass der RabbitMQ-Server gezwungen ist alle Weiterleitungsoptionen zu Prüfen, auch wenn diese keinem Ziel entsprechen.
		}{%
		 -lh (Aufrufparameter für Angriff) \\
		 -i 10 (10ms Pause zwischen 2 Anfragen)
		 -ms 10000 (Nachrichtengröße: 10000 Byte) \\
		 -hs 2500 (Headergröße - Anzahl Einträge in Map) \\
		 -u <uri> (URI für Verbindung mit Server)
		}{%
		 Amqpstress -lh -i 10 -ms 10000 -hs 2500 -u amqp://\\\hspace*{3cm}testc:testp@192.168.178.153:5672/\%2f
		}

		
	\attack{Channel-Flooding}%
		{%
		 Neben einzelnen Connections können Clients zu einem RabbitMQ-Server auch mehrere Channel aufbauen. Hier stellt sich die Frage, wie der RabbitMQ-Server mit einer Vielzahl von Channeln zurecht kommt.
		 Auf Basis einer einzelnen Connection wird das System so ausgelastet und beobachtet.
		}{%
		 -mc (Aufrufparameter für Angriff) \\
		 -p 100 (100 Producer) \\
		 -c 10 (10 Consumer) \\
		 -ms 10000 (Nachrichtengröße: 10000 Byte) \\
		 -u <uri> (URI für Verbindung mit Server) \\		 
		}{%
		 Amqpstress -mc -p 100 -c 10 ms 10000 -u amqp://\\\hspace*{3cm}testc:testp@192.168.178.153:5672/\%2f
		}


	\attack{Ausbleiben von Commits im Transaktionsmodus}%
		{%
		 Im Transaktionsmodus ist es möglich mehrere Nachrichten als Folge zu übertragen, die, analog zu Transaktionen einer Datenbanken, als Einheit betrachtet werden. Nur durch die Commit()-Funktion
		 wird der neue Zustand angenommen und die Nachrichten im System zur Verfügung gestellt. Ferner kann mit der Rollback()-Funktion der ursprüngliche Zustand wiederhergestellt werden.
		 Zu untersuchen wäre die Situation, wenn permanent Nachrichten ohne commit gesendet werden - der Server muss die Nachrichten dann im Speicher belassen.
		}{%
		 -tx (Aufrufparameter für Angriff) \\
		 -p 5 (5 Producer) \\
		 -ms 10240 (Nachrichtengröße: 10KB) \\
		 -mct 100000 (Nachrichtenanzahl pro Producer: 100000) \\
		 -u <uri> (URI für Verbindung mit Server) \\
		 Commit auslassen (Standard)
		}{%
		 Amqpstress -tx -p 5 ms 10240 -mct 100000 -u amqp://\\\hspace*{3cm}testc:testp@192.168.178.153:5672/\%2f
		}
	
	
	\attack{Handshake-Trickle}%
		{%
		 Der Handshake zum Aufbau einer Connection zwischen Client und RabbitMQ-Server erfolgt in 9 Schritten. Ziel des Angriffes ist es, gezielt Pausen in den Protokollablauf einzubauen und die
		 Auswirkungen auf Server sowie andere Clients zu beobachten.
		}{%
		 -sh (Aufrufparameter für Angriff) \\
		 -i 0 (Keine Pause zwischen 2 Handshakes) \\
		 -cl 20 (20 Clients) \\
		 -u <uri> (URI für Verbindung mit Server) \\
		 1s Pause in jedem Schritt (Standard) 
		}{%
		 Amqpstress -sh -i 0 -cl 20 -u amqp://\\\hspace*{3cm}testc:testp@192.168.178.153:5672/\%2f
		}


	\attack{Heartbeat-Flooding}%
		{%
		 Damit ein RabbitMQ-Server clientseitig geschlossene TCP-Verbindungen erkennen kann (sowie vice versa), werden periodisch Heartbeats an die Clients gesendet. Dabei sendet der Server bei der Hälfte des
		 eingestellten Timeouts einen Heartbeat an den Client. Sofern er keine Rückmeldung erhält sendet der Server einen zweiten Heartbeat bei erreichen des Timeouts und schließt ggf. die TCP-Verbindung. Ziel dieses Angriffes ist Reduzierung des Heartbeat-Timeouts auf ein Minimum, um anschließend die Auswirkungen auf den Server und die Clients zu beobachten. 
		}{%
		 -hb (Aufrufparameter für Angriff) \\
		 -i 1 (1s Heartbeat Timeout) \\
		 -cl 20 (20 Clients) \\
		 -u <uri> (URI für Verbindung mit Server)
		}{%
		 Amqpstress -hb -i 1 -cl 20 -u amqp://\\\hspace*{3cm} testc:testp@192.168.178.153:5672/\%2f
		}


	\attack{TCP-Connection-Dropping}%
		{%
		 Im Vergleich mit den restlichen Angriffen, setzt dieser Angriff weiter unten im Netzwerkstack an und versucht direkt auf TCP-Ebene die Connections zu schließen. Hierbei wird der TCP-Socket zu einer 
		 Connection ermittelt und stillschweigend geschlossen, sodass der RabbitMQ-Server erst nach Erreichen des Heartbeat-Timeout die Connection schließen kann. Die Connections werden in hoher Frequenz aufgebaut
		 geschlossen, sodass der RabbitMQ-Server durch die hängenden Connections belastet ist. \medskip\newline
		 \textsc{Anmerkung:} Beim Schließen des TCP-Sockets wird ein RST-Packet an den Server gesendet, was sich mit Java-Bordmitteln nicht unterbinden lässt, deshalb ist die Einrichtung einer Firewall-Richtlinie zum
		 Blocken der RST-Packeten notwendig (dropRST.sh)\footnotemark[5].
		}{%
		 -dc (Aufrufparameter für Angriff) \\
		 -i 100 (100ms Pause zwischen Connection Erzeugung) \\
		 -u <uri> (URI für Verbindung mit Server)
		}{%
		 Amqpstress -dc -i 100 -u amqp://\\\hspace*{3cm}testc:testp@192.168.178.153:5672/\%2f\\
		 sudo bash dropRST.sh -i eth0 192.168.178.153 5672
		}
	\footnotetext[5]{\url{https://github.com/philippsied/amqp-stress-test/tree/master/utilities/dropRST.sh}}


% ---------------------------------------------------------------------------------------------- %
%	
% -------------------------------- Auswirkungen der Angriffe ----------------------------------- %
%
% ---------------------------------------------------------------------------------------------- %
\clearpage
\section*{Auswirkungen der Angriffe}
	
	\report{Referenzangriff - Kooperativer Client}%
		{%
		 \measure{CPU}{13\%} \newline
		 \measure{RAM}{134MB (Verwendet)} \newline
		 \measure{HDD}{785MB (Frei)} \newline
		 \measure{NET}{RCX 5Mbit/s\quad TRX 42.8Mbit/s}
		}{%
		 Es ist keine Beeinträchtigung erkennbar. Die Nachrichtenraten liegen jeweils konstant bei 50 Nachrichten/s und die Latenz liegt bei durchschnittlich 1.3 ms.
		 (Siehe Abb. \ref{fig:ack-scenario}).
		}{%
		 Keine
		}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/ack/ack_server1.png}
			\caption{Kooperativer Client - Verlauf des Speicherbedarfs für RAM/HDD und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:ack-server1}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/ack/ack_server2.png}
			\caption{Kooperativer Client - Verlauf der Transfer-, Empfangsrate und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:ack-server2}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/ack/ack_scenario.png}
			\caption{Kooperativer Client - Verlauf der Transfer-, Empfangsrate und Verlauf der Latenz im Anwendungsszenario}
			\label{fig:ack-scenario}
		\end{figure}
	
	
%-------------------------------------------------------------------------------------------
	\clearpage
	\report{Ignorieren von Nachrichten}
		{%
		 \measure{CPU}{9\%} \newline
		 \measure{RAM}{362MB (Verwendet)} \newline
		 \measure{HDD}{593MB (Frei)} \newline
		 \measure{NET}{RCX 3.8Mbit/s\quad TRX 33.8Mbit/s}
		}{%
		 Die Nachrichten werden bis zur Hälfte des eingestellten Limits (hier ~500MB) im RAM gehalten, bei überschreiten der Grenze lagert der RabbitMQ-Server die Nachrichten im Hintergrund auf die Festplatte aus.
		 Hierbei entsteht eine CPU-Lastspitze, welche in Abb. \ref{fig:no-server1} deutlich bei ca. 260s zu sehen ist und sich direkt auf die Latenz im Anwendungsszenario auswirkt (Siehe Abb. \ref{fig:no-scenario}). Durch die Freigabe des RAM-Speichers entsteht ein Sägezahnmuster. Dieser Vorgang wiederholt sich bis der standardmäßig gesetzte Schwellwert erreicht ist und der Server alle Verbindungen schließt und in diesem Zustand verweilt. Der Ressourcenverbrauch sinkt auf den Leerlauf-Zustand. Davor lag die Latenz bei durchschnittlich ca. 1.4ms. Die Übertragungsraten (Daten/Nachrichten) decken sich weitgehend mit denen des Referenzszenarios.
		}{%
		 In der aktuellen Implementierung des Angriffes hat der Client ebenfalls einen hohen Bedarf an Arbeitsspeicher, da die Client-Bibliothek die empfangene Nachricht für jeden Consumer
		 separat zwischenspeichert. Dies lässt sich durch den Umfang des Prefetching einstellen.
		}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/no/no_server1.png}
			\caption{Ignorieren von Nachrichten - Verlauf des Speicherbedarfs für RAM/HDD und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:no-server1}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/no/no_server2.png}
			\caption{Ignorieren von Nachrichten - Verlauf der Transfer-, Empfangsrate und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:no-server2}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/no/no_scenario.png}
			\caption{Ignorieren von Nachrichten - Verlauf der Transfer-, Empfangsrate und Verlauf der Latenz im Anwendungsszenario}
			\label{fig:no-scenario}
		\end{figure}
	
	
%-------------------------------------------------------------------------------------------
	\clearpage
	\report{Sofortiges Abweisen von Nachrichten}%
		{%
		 \measure{CPU}{24\%} \newline
		 \measure{RAM}{467MB (Verwendet)} \newline
		 \measure{HDD}{603MB (Frei)} \newline
		 \measure{NET}{RCX 4.2Mbit/s\quad TRX 28.2Mbit/s}
		}{%
		 Der Beginn ähnelt den Beobachtungen beim Ignorieren der Nachrichten. So wird zunächt der RAM gefüllt bis die eingestellte Grenze erreicht wird, um die Daten auf die Festplatte auszulagern (Siehe Abb.  \ref{fig:reject-server1}, \ref{fig:reject-server2}).
		 Die CPU-Auslastung ist hierbei jedoch höher. Zudem sind die Übertragungsraten im Vergleich zum Referenzszenario \glqq unruhiger\grqq. Die Latenz ist insgesamt leicht erhöht und steigt nach 
		 dem Beginn des Auslagerns auf die Festplatte weiter an. Sobald der verfügbare Festplattenspeicher erschöpft ist, bricht der RabbitMQ-Server die Verbindungen ab (Siehe Abb. \ref{fig:reject-scenario}).
		 Weshalb der Speicherbedarf über die Grenze hinauswächst ist unklar (Siehe Abb. \ref{fig:reject-server1}, ca. 510s). Die Autoren vermuten, dass für abgewiesen Nachrichten andere Puffer verwendet werden,
		 welche nicht auf die Festplatte ausgelagert werden können bzw. dürfen.
		}{%
		 In der aktuellen Implementierung des Angriffes hat der Client ebenfalls einen hohen Bedarf an Arbeitsspeicher, da die Client-Bibliothek die empfangene Nachricht für jeden Consumer
		 separat zwischenspeichert. Dies lässt sich durch den Umfang des Prefetching einstellen.
		}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/reject/reject_server1.png}
			\caption{Sofortiges Abweisen von Nachrichten - Verlauf des Speicherbedarfs für RAM/HDD und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:reject-server1}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/reject/reject_server2.png}
			\caption{Sofortiges Abweisen von Nachrichten - Verlauf der Transfer-, Empfangsrate und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:reject-server2}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/reject/reject_scenario.png}
			\caption{Sofortiges Abweisen von Nachrichten - Verlauf der Transfer-, Empfangsrate und Verlauf der Latenz im Anwendungsszenario}
			\label{fig:reject-scenario}
		\end{figure}
	
	
%-------------------------------------------------------------------------------------------
	\clearpage
	\report{Gebündeltes Abweisen von Nachrichten}%
		{%
		 \measure{CPU}{15\%} \newline
		 \measure{RAM}{534MB (Verwendet)} \newline
		 \measure{HDD}{572MB (Frei)} \newline
		 \measure{NET}{RCX 4.2Mbit/s\quad TRX 81.8Mbit/s}
		}{%
		 Wie in den vorangegangen Szenarien, werden die Nachrichten bis zum Schwellwert im RAM gehalten, wobei sie bei Erreichen des Schwellwertes auf die Festplatte ausgelagert werden.
		 Zeitgleich werden kontinuierlich Nachrichten vom RabbitMQ-Server an die Consumer gesendet, die diese zunächst Ignorieren. Das gebündelte Abweisen seites der Consumer kann der Abb.
		 \ref{fig:nack-server2} und den Peaks im Verlauf der Latenz in Abb. \ref{fig:nack-scenario} sehr gut entnommen werden. Nachdem der Server keinen freien Festplattenspeicher mehr zur 
		 Verfügung hat, schließt er die Verbindungen, wobei der Bedarf an RAM weiter steigt. Weshalb der Speicherbedarf über die Grenze hinauswächst ist unklar (Siehe Abb. \ref{fig:nack-server1}, ca. 510s).
		 Die Autoren vermuten, dass für abgewiesen Nachrichten andere Puffer verwendet werden, welche nicht auf die Festplatte ausgelagert werden können bzw. dürfen.
		}{
		 In der aktuellen Implementierung des Angriffes hat der Client ebenfalls einen hohen Bedarf an Arbeitsspeicher, da die Client-Bibliothek die empfangene Nachricht für jeden Consumer
		 separat zwischenspeichert. Dies lässt sich durch den Umfang des Prefetching einstellen.
		}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/nack/nack_server1.png}
			\caption{Gebündeltes Abweisen von Nachrichten - Verlauf des Speicherbedarfs für RAM/HDD und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:nack-server1}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/nack/nack_server2.png}
			\caption{Gebündeltes Abweisen von Nachrichten - Verlauf der Transfer-, Empfangsrate und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:nack-server2}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/nack/nack_scenario.png}
			\caption{Gebündeltes Abweisen von Nachrichten - Verlauf der Transfer-, Empfangsrate und Verlauf der Latenz im Anwendungsszenario}
			\label{fig:nack-scenario}
		\end{figure}
	
	
%-------------------------------------------------------------------------------------------
	\clearpage
	\report{Queue-Churning}%
		{%
		 \measure{CPU}{44\%} \newline
		 \measure{RAM}{1542MB (Verwendet)} \newline
		 \measure{HDD}{784MB (Frei)} \newline
		 \measure{NET}{RCX 265kbit/s\quad TRX 358kbit/s}
		}{%
		 Direkt zu Beginn steigen sowohl der Bedarf an RAM als auch die CPU-Auslastung sprunghaft an. Auffallend ist, dass der für das Speichern von Nachrichten gesetzte Schwellwert bei ca. 500MB,
		 nicht für die Speicherung von Queues gilt und kein Festplattenspeicher verwendet wird. Der RAM-Bedarf steigt somit kontinuierlich an, bis er an das physisch (bzw. virtuell) gesetzte Limit stößt. Bereits bei Überschreiten der 1GB RAM-Grenze
		 schließt der RabbitMQ-Server alle Verbindungen und verweilt in diesem Zustand, wobei weitere Kommunikation abgelehnt wird (Siehe Abb.\ref{fig:queue-scenario}).
		}{%
		 Der Angriff wurde einige Sekunden zu früh manuell beendet, was in dem Abfallen des Ressourcenverbrauches und den Peaks in der 560s in Abbildungen \ref{fig:queue-server1}, \ref{fig:queue-server2}
		 und \ref{fig:queue-scenario} zu sehen ist.
		}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/queue/queue_server1.png}
			\caption{Queue-Churning - Verlauf des Speicherbedarfs für RAM/HDD und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:queue-server1}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/queue/queue_server2.png}
			\caption{Queue-Churning - Verlauf der Transfer-, Empfangsrate und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:queue-server2}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/queue/queue_scenario.png}
			\caption{Queue-Churning - Verlauf der Transfer-, Empfangsrate und Verlauf der Latenz im Anwendungsszenario}
			\label{fig:queue-scenario}
		\end{figure}
	
	
%-------------------------------------------------------------------------------------------
	\clearpage
	\report{Ausbleiben von Commits im Transaktionsmodus}%
		{
		 \measure{CPU}{2\%} \newline
		 \measure{RAM}{955MB (Verwendet)} \newline
		 \measure{HDD}{785MB (Frei)} \newline
		 \measure{NET}{RCX 924kbit/s\quad TRX 83bit/s}%
		}{
		 Durch Auslassen des Commits steigt der Speicherverbrauch stark an. Nach wenigen Sekunden ist die Speichergrenze erreicht und es werden keine weiteren Nachrichten übertragen. Daraufhin verharren alle Producer bis der Speicher wieder freigegeben wird (Falls Consumer vorhanden).
		}{
		 Die vollständige Messung des Andwendungsszenario konnte bei diesem Angriff nicht durchgeführt werden, da das dafür verwendete Tool \glqq HTML Performance Tools\grqq\ bei der Messung reproduzierbar einfriert. Sporadisch friert ebenfalls der RabbitMQ-Server bei diesem Versuch ein. Ein Aufbau einer neuen Verbindung schlägt fehl und die Weboberfläche ist nicht mehr erreichbar. Nach längerer Zeit (etwa 10 Minuten) baut der Server aber wieder die Verbindungen ab und ein Zugriff ist wieder möglich. Dennoch bleibt der Speicherverbrauch bestehen. Die Autoren vermuten, dass der RabbitMQ-Server wegen seines maßlosen    Ressourcenbedarfes durch das Betriebssystem der VM teilweise abgewürgt wird. 

		}

		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/tx/tx_server1.png}
			\caption{Ausbleiben von Commits im Transaktionsmodus - Verlauf des Speicherbedarfs für RAM/HDD und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:tx-server1}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/tx/tx_server2.png}
			\caption{Ausbleiben von Commits im Transaktionsmodus - Verlauf der Transfer-, Empfangsrate und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:tx-server2}
		\end{figure}
		
		
	
	
%-------------------------------------------------------------------------------------------
	\clearpage
	\report{Nachrichten mit großem Header}%
		{%
		 \measure{CPU}{2\%} \newline
		 \measure{RAM}{468MB (Verwendet)} \newline
		 \measure{HDD}{391MB (Frei)} \newline
		 \measure{NET}{RCX  2.8Mbit/s\quad TRX 33kbit/s}%
		}{%
		 Die Anwendung generiert zu Beginn 2500 Weiterleitungsoptionen (Bestehend aus 8 Byte Key und 36 Byte Value = 44 Byte pro Eintrag) und schreibt sie in den Header jeder Nachricht. Hierdurch ist der
		 RabbitMQ-Server blitzartig massiv ausgelastet, versucht jedoch die Nachrichten auf die Festplatte auszulagern. Die Datenübertragungsrate sinkt dabei auf 20-30 Nachrichten/s. Hierbei macht es
		 keinen Unterschied ob der Key oder Value vergrößert wird, die geringe Übertragungsrate bleibt bestehen. Der Value wird daher nicht ausgewertet. Die Headergröße ist bei etwa 2500
		 Weiterleitungsoptionen begrenzt. Wird diese überschritten lässt das System die Verbindung fallen, aufgrund einer zu großen Framegröße. Die Framegröße lässt sich beim Aufbau der
		 Verbindung angeben, kann aber die bereits voreingestellten eingestellten 128 Byte nicht überschreiten.
		}{%
		  Die vollständige Messung des Andwendungsszenario konnte bei diesem Angriff nicht durchgeführt werden, da das dafür verwendete Tool \glqq HTML Performance Tools\grqq\ bei der Messung reproduzierbar einfriert. Die Autoren vermuten, dass der RabbitMQ-Server wegen seines maßlosen    Ressourcenbedarfes durch das Betriebssystem der VM teilweise abgewürgt wird. 
		}

		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/header/header_server1.png}
			\caption{Nachrichten mit großem Header - Verlauf des Speicherbedarfs für RAM/HDD und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:header-server1}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/header/header_server2.png}
			\caption{Nachrichten mit großem Header - Verlauf der Transfer-, Empfangsrate und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:header-server2}
		\end{figure}
				
		\begin{table}[!htb]
			\centering
			\begin{tabular}{p{3cm}ll|p{3cm}}
				\multicolumn{3}{l|}{Übertragungsrate nach Nachrichtengröße}  & Headergröße     \\
				10.000 Byte          & 1.000 Byte              & 100 Byte    & Einträge (Byte) \\ \hline
				140m/s               & 260m/s                  & 350m/s      & 200 (8.800)     \\
				80m/s                & 120m/s                  & 180m/s      & 500 (22.000)    \\
				30m/s                & 50m/s                   & 70m/s       & 1.000 (44.000)  \\
				20m/s                & 30m/s                   & 40m/s       & 2.000 (88.000)  \\
				10m/s                & 10m/s                   & 20m/s       & 2.500 (110.000) \\ \hline
				270m/s               & 3.000m/s                & 10.000m/s   & kein Eintrag
			\end{tabular}
			\caption{Vergleich Headergröße}
		\end{table}
	
	
%-------------------------------------------------------------------------------------------
	\clearpage
	\report{Channel-Flooding}%
		{%
		 \measure{CPU}{76\%} \newline
		 \measure{RAM}{298MB (Verwendet)} \newline
		 \measure{HDD}{785MB (Frei)} \newline
		 \measure{NET}{RCX 116.7Mbit/s\quad TRX 205.0Mbit/s}
		}{%
		 Das System ist stark ausgelastet, ähnelt aber der Auslastung unter der Erstellung mehrerer Verbindungen. Allerdings beansprucht der Aufbau der Channel verhältnismäßig viel Zeit.
		 Die Datenübertragungsrate steigt mit der Anzahl der Channel, wobei die CPU-Auslastung ebenfalls steigt (Siehe Abb. \ref{fig:channel-server1},\ref{fig:channel-server2}).
		 Bedingt durch die hohe CPU-Beanspruchung, verdoppelt sich die Latenz im Anwendungsszenario,
		 wobei vereinzelt Peaks entstehen (Siehe Abb. \ref{fig:channel-scenario}).
		}{%
		 Die Zeit für den Aufbau der Channel hängt stark von der Anzahl von Producer und Consumer ab. Nachfolgend zeigt sich ein Vergleich von mehreren Kanälen sowie mehreren Verbindungen.
		}

		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/channel/channel_server1.png}
			\caption{Channel-Flooding - Verlauf des Speicherbedarfs für RAM/HDD und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:channel-server1}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/channel/channel_server2.png}
			\caption{Channel-Flooding - Verlauf der Transfer-, Empfangsrate und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:channel-server2}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/channel/channel_scenario.png}
			\caption{Channel-Flooding - Verlauf der Transfer-, Empfangsrate und Verlauf der Latenz im Anwendungsszenario}
			\label{fig:channel-scenario}
		\end{figure}
		
		\begin{table}[!htb]
			\centering
			\begin{tabular}{p{3cm}llp{3cm}}
				Übertragungsrate\newline (schreiben) & Producer & Consumer & Nachrichtengröße\newline (Byte) \\ \hline
				7.000m/s                             & 100      & 10       & 100                              \\
				800m/s                               & 100      & 10       & 1.000                            \\
				100m/s                               & 100      & 10       & 10.000
			\end{tabular}
			\caption{Mehrere Channel}
		\end{table}

		\begin{table}[!htb]
			\centering
			\begin{tabular}{p{3cm}llp{3cm}}
				Übertragungsrate\newline (schreiben) & Producer & Consumer & Nachrichtengröße\newline (Byte) \\ \hline
				24.000m/s                            & 100      & 10       & 100                             \\
				2.000m/s                             & 100      & 10       & 1.000                           \\
				100m/s                               & 100      & 10       & 10.000
			\end{tabular}
			\caption{Mehrere Connections}
		\end{table}
	
	
%-------------------------------------------------------------------------------------------
	\clearpage
	\report{Handshake-Trickle}%
		{%
		 \measure{CPU}{2\%} \newline
		 \measure{RAM}{125MB (Verwendet)} \newline
		 \measure{HDD}{785MB (Frei)} \newline
		 \measure{NET}{RCX 293kbit/s\quad TRX 355kbit/s}
		}{%
		 Die Auswirkungen des Angriffes sind kaum wahrnehmbar und unterscheiden sich nur marginal von der alleinigen Ausführung des Anwendungsszenarios.
		 Selbst bei 20 parallel laufenden Handshakes ist die Auswirkung kaum verändert.\newline
		 
		 Der Angriff könnte jedoch, in Analogie zum \glqq Sync-Flooding\grqq\ bei TCP, dazu umgebaut werden, das der Handshake lediglich gestartet wird, um ihn anschließend ohne Rückmeldung zu schließen.
		 Dabei wird für mindestens 10s ein TCP-Socket des Servers blockiert, was den Server schnell an die Grenze der zur Verfügung stehenden Socketdeskriptoren bringt.
		}{%
		 Da im RabbitMQ-Server standardmäßig ein Handshake-Timeout von 10s gesetzt ist, verwendet der vorliegende Angriff jeweils 9 Pause
		 zu je 1s. Dabei wurde ebenfalls versucht den Timeout auf 30s hochzusetzen, was vom Server jedoch ignoriert wurde.
		}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/handshake/handshake_server1.png}
			\caption{Handshake-Trickle - Verlauf des Speicherbedarfs für RAM/HDD und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:handshake-server1}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/handshake/handshake_server2.png}
			\caption{Handshake-Trickle - Verlauf der Transfer-, Empfangsrate und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:handshake-server2}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/handshake/handshake_scenario.png}
			\caption{Handshake-Trickle - Verlauf der Transfer-, Empfangsrate und Verlauf der Latenz im Anwendungsszenario}
			\label{fig:handshake-scenario}
		\end{figure}
	
	
%-------------------------------------------------------------------------------------------
	\clearpage
	\report{Heartbeat-Flooding}%
		{%
		 \measure{CPU}{4\%} \newline
		 \measure{RAM}{134MB (Verwendet)} \newline
		 \measure{HDD}{785MB (Frei)} \newline
		 \measure{NET}{RCX 318kbit/s\quad TRX 386kbit/s}
		}{%
		 Die Auswirkungen des Angriffes sind kaum wahrnehmbar und unterscheiden sich nur marginal von der alleinigen Ausführung des Anwendungsszenarios. So ist die CPU-Auslastung und
		 die Netzwerkauslastung etwas erhöht, wobei der Peak zu Beginn der Messung durch die Erzeugung der 20 Connections verursacht wurde. Die Latenz sowie die Nachrichtenraten sind im
		 Anwendungsszenario weitgehen konstant. \medskip\newline
		 \textsc{Ergänzung:} Es wurde eine Vergleichsmessung mit dem Standard-Heartbeat von 580s durchgeführt, was zu einer Halbierung der CPU-Auslastung (2\%) und einer minimalen
		 Verbesserung der Latenz geführt hat. Die Netzwerkauslastung hat sich erwartungsgemäß ebenfalls verringert. 
		}{%
		 Während der Tests wurde versucht, den Heartbeat auf den maximal möglichen Wert zu setzen. Der RabbitMQ-Server ignoriert jedoch alle Anfragen, die darauf Abzielen den Heartbeat auszusetzen oder ihn
		 höher als auf 580s zu setzen. Somit ist der Heartbeat stets ein Wert zwischen 1 und 580s.
		}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/heartbeat/heartbeat_server1.png}
			\caption{Heartbeat-Flooding - Verlauf des Speicherbedarfs für RAM/HDD und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:heartbeat-server1}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/heartbeat/heartbeat_server2.png}
			\caption{Heartbeat-Flooding - Verlauf der Transfer-, Empfangsrate und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:heartbeat-server2}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/heartbeat/heartbeat_scenario.png}
			\caption{Heartbeat-Flooding - Verlauf der Transfer-, Empfangsrate und Verlauf der Latenz im Anwendungsszenario}
			\label{fig:heartbeat-scenario}
		\end{figure}
	
	
%-------------------------------------------------------------------------------------------
	\clearpage
	\report{TCP-Connection-Dropping}%
		{%
		 \measure{CPU}{2\%} \newline
		 \measure{RAM}{416MB (Verwendet)} \newline
		 \measure{HDD}{785MB (Frei)} \newline
		 \measure{NET}{RCX 303kbit/s\quad TRX 522kbit/s}
		}{%
		 Mit steigender Anzahl an unbemerkt geschlossenen Connections, steigt auch der Bedarf an TCP-Sockets auf dem Server. Das überschreiten des Schwellwertes geht deutlich bei der 150. Sekunde aus Abb. \ref{fig:tcpdrop-server1}
		 hervor. Danach werden keine neuen Connections mehr akzeptiert, weshalb der Speicherbedarf weitgehend konstant ist. Da gegen Ende der Messung die ersten Verbindungen durch den Heartbeat-Timeout geschlossen werden, können kurzzeitig neue Verbindungen aufgebaut werden. Aus Abbildung \ref{fig:tcpdrop-scenario} geht dabei hervor, dass einzig die Latenz in dem Moment der Überschreitung des Socketdeskriptoren-Schwellwertes kurzzeitig beeinflusst wird. 
		}{%
		 In der Testumgebung standen exakt 1024 Filedeskriptoren zur Verfügung, wovon 829 für Sockets reserviert waren.
		}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/tcpdrop/tcpdrop_server1.png}
			\caption{TCP-Connection-Dropping - Verlauf des Speicherbedarfs für RAM/HDD und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:tcpdrop-server1}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/tcpdrop/tcpdrop_server2.png}
			\caption{TCP-Connection-Dropping - Verlauf der Transfer-, Empfangsrate und Verlauf der CPU-Last auf dem RabbitMQ-Server}
			\label{fig:tcpdrop-server2}
		\end{figure}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=\textwidth]{img/tcpdrop/tcpdrop_scenario.png}
			\caption{TCP-Connection-Dropping - Verlauf der Transfer-, Empfangsrate und Verlauf der Latenz im Anwendungsszenario}
			\label{fig:tcpdrop-scenario}
		\end{figure}
		
		
\clearpage
\section*{Ausblick}
	Die hier gezeigten Angriffsszenarien stellen lediglich eine kleinen Ausschnitt der denkbaren Angriffe dar. Hierbei wurden zum Teil bekannte Angriffe auf andere Protokollen adaptiert und ggf. ausgebaut.
	So existieren in der Literatur jedoch weitere Angriffe z.\,B. für das TCP. Nachfolgend wird eine kleine Auswahl der Angriffe beschrieben und deren mögliche Adaptierung auf das AMQP diskutiert. 

	\paragraph{SYN Flood-Angriff} \ \\
		SYN-Flooding ist eines der ältesten Angriffe auf TCP und dennoch aktuell sowie von großer Bedeutung. Bei dem Aufbau einer Verbindung zwischen Client und Server wird ein 3-Wege-Handshake durchgeführt. Die Idee hinter diesem Angriff ist es möglichst viele SYN-Pakete zu versenden, um so die Ressourcen des Servers auszulasten. Durch das Ignorieren der Rückantwort (ACK) des Angreifers, wird der Server dennoch gezwungen die Ressourcen für die Verbindung zu allokieren und muss bis zum Timeout des Handshake warten.

		Die SYN-Pakete sind einfach zu erzeugen und entsprechend klein. Hierdurch ist es möglich den Server schnell auszulasten und somit einen Denial-of-Service (DoS) zu bezwecken. Auch bei einem RabbitMQ-Server ist dieser Angriff möglich, denn jede offene Anfrage zum Aufbauen einer Verbindung wird für 10 Sekunden gehalten. Genügend Zeit um alle Socket-Deskriptoren zu belegen. Auf dem verwendetem
		Test-System stehen lediglich 1024 zur Verfügung, welche bereits nach wenigen Sekunden ausgeschöpft werden können. Das bedeutet, dass für eine ernst gemeinte Verbindung keine Ressourcen mehr zur Verfügung stehen. Die Wartezeit lässt sich über die config-Datei \glqq rabbitmq.config\grqq\ beliebig anpassen, bietet dennoch keinen Schutz vor diesen Angriff.

\clearpage
\section*{Zusammenfassung}

	Zusammenfassend hat sich RabbitMQ in der getesteten Version (3.5.3) als ein sehr stabiler Message-Broker erwiesen. Dennoch zeigten sich unter allen getesteten Angriffsvektoren potenzielle Schwachstellen,
	die zum Teil einen gravierenden Einfluss auf den Server selbst sowie auf andere Clients haben. Der Großteil der Angriffe beruhte auf der Steigerung des Ressourcenbedarfs bis die im Server konfigurierten
	Schwellwerte erreicht werden. Dabei lagen die Ansatzpunkte nicht in der Ausnutzung von Softwarefehlern sondern vorranging im Missbrauch der angefragten Konfiguration für das Prefetching, den Heartbeat,
	die Framegröße, die Headergröße, der Anzahl der Queues, Channel, Connections, Transaktionen, Nachrichten und Nachrichtengrößen. Außerdem fiel auf, dass die im Server gesetzten Grenzwerte für Hauptspeicherbedarf teilweise nicht für Queues oder Transaktionen griffen, weshalb auch andere Dienste auf dem Server beeinträchtig werden könnten.
	
	Die Empfehlung der Autoren lautet deshalb, dass die Konfiguration hinsichtlich Konfigurations-Anfragen durch den Client kritisch überdacht werden sollte und zusammen mit den Schwellwerten an das 
	Einsatzgebiet des RabbitMQ-Server angepasst und eingeschränkt werden sollten. So kann z.\,B. der standardmäßig gesetzte Heartbeat von ca. 10min oder der Handshake-Timeout von 10s in Umgebungen
	mit einer leistungsfähigen Netzwerkinfrastruktur problemlos reduziert werden. Weiterhin sollten die gesetzte Ressourcen-Limits für jedwede Funktionalität des Servers verbindlich sein, um bessere
	Vorhersagen bzgl. des Ressourcenbedarfs bzw. der Beeinflussung von anderen Diensten treffen zu können.



\end{document}
